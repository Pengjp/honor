{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "rEP8Ti9V-1B4"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import optimizers, layers, Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, LeakyReLU,Conv1D,Dropout,MaxPooling1D,SimpleRNN\n",
    "from tensorflow.keras.layers import Flatten,ReLU, BatchNormalization,GlobalAveragePooling1D\n",
    "import numpy as np\n",
    "\n",
    "def runif():\n",
    "    return tf.random.uniform([1], dtype=tf.float64)[0]\n",
    "    # return tf.constant(.8, tf.float32)\n",
    "\n",
    "def rexp():\n",
    "    return -tf.math.log(runif())\n",
    "\n",
    "\n",
    "def exprelu(x):\n",
    "    return tf.where(x > 0, tf.math.expm1(x), tf.zeros_like(x))\n",
    "\n",
    "def reloid(x):\n",
    "    \"(sigma(x[1]), ..., sigma(x[-2]), relu(x[-1])\"\n",
    "    return tf.concat([tf.nn.sigmoid(x[:-1]), tf.math.exp(x[-1:])], axis=0)\n",
    "\n",
    "def reloid_derivative(x):\n",
    "    return tf.concat(\n",
    "        [\n",
    "            tf.nn.sigmoid(x[:-1])\n",
    "            * (1 - tf.nn.sigmoid(x[:-1])),  # derivative of sigmoid\n",
    "            tf.math.exp(x[-1:]),\n",
    "        ],\n",
    "        axis=0,\n",
    "    )\n",
    "\n",
    "def S(x, w, v, b):\n",
    "    \"\"\"\n",
    "    x: scalar\n",
    "    w, v, b: (3, H)\n",
    "    \"\"\"\n",
    "    x = tf.convert_to_tensor(x, dtype=\"float64\")\n",
    "    # tf.debugging.assert_positive(x, message=\"R: x>0\")\n",
    "    exp_w_v = tf.math.exp([w, v])\n",
    "    ew = exp_w_v[0]\n",
    "    ev = exp_w_v[1]\n",
    "    # b = tf.math.sigmoid(b) # try this  # JT - bug. was sigb\n",
    "    ew = tf.concat([ew[:-1], tf.ones_like(ew[-1:]),], axis=0,)\n",
    "    x = tf.reshape(x, (1, 1))\n",
    "    return tf.transpose(ev) @ reloid(ew @ x + b)\n",
    "\n",
    "@tf.function\n",
    "def R(x, w, v, b):\n",
    "    return S(tf.math.log(x), w, v, b)\n",
    "\n",
    "@tf.function\n",
    "def Rinv(y, w, v, b):\n",
    "    y = tf.convert_to_tensor(y, dtype=\"float64\")\n",
    "    # y = tf.reshape(y, (-1,))[0]\n",
    "    # as x -> oo, R is asymyptotic to exp(v[-1] + w[-1]) x\n",
    "    # fixme: calculate this exactly.\n",
    "    x_left = tf.convert_to_tensor([[0.0]], tf.float64)\n",
    "    x_right = tf.convert_to_tensor([[1e8]], tf.float64)\n",
    "    # tf.print((x_left, x_right))\n",
    "    # tf.print(\"y\", y)\n",
    "    # tf.print('y',y)\n",
    "    # tf.debugging.assert_greater(R(x_right, w, v, b), y, message=\"R(x_right)>y inv\")\n",
    "\n",
    "    def cond(xl, xr):\n",
    "        # tf.print(xl, xr)\n",
    "        xi = (xl + xr) / 2.0\n",
    "        yi = R(xi, w, v, b)[0, 0]\n",
    "        return abs(y - yi) > 1e-6\n",
    "\n",
    "    def body(xl, xr):\n",
    "        xi = (xl + xr) / 2.0\n",
    "        yi = R(xi, w, v, b)[0, 0]\n",
    "        left = tf.cast(yi < y, dtype=\"float64\")\n",
    "        xl = left * xi + (1.0 - left) * xl\n",
    "        xr = (1.0 - left) * xi + left * xr\n",
    "        return (xl, xr)\n",
    "        # print(y, x_i, y_i)\n",
    "\n",
    "    xl, xr = tf.while_loop(cond, body, (x_left, x_right))\n",
    "    return (xl + xr) / 2.0\n",
    "\n",
    "@tf.custom_gradient\n",
    "def custom_Rinv(y, w, v, b):\n",
    "    y = tf.convert_to_tensor(y, dtype=\"float64\")\n",
    "    x = Rinv(y, w, v, b)\n",
    "    with tf.GradientTape() as g:\n",
    "        g.watch([x, w, v, b])\n",
    "        y = R(x, w, v, b)\n",
    "    dR_dw, dR_dv, dR_db, dR_dx = g.gradient(y, [w, v, b, x])\n",
    "\n",
    "    def grad(dx):\n",
    "        return dx / dR_dx, -dx * dR_dw / dR_dx, -dx * dR_dv / dR_dx, -dx * dR_db / dR_dx\n",
    "\n",
    "    return x, grad\n",
    "\n",
    "mu = 1e-4\n",
    "rho = 1e-5\n",
    "\n",
    "def _gen_gaps(k: int, _R, _Rinv,) -> tf.Tensor:\n",
    "    \"\"\"Return k gaps sampled from genetic distribution with rate function eta.\"\"\"\n",
    "    z = tf.convert_to_tensor([[rexp()]])\n",
    "    x = _Rinv(z)  # initialize x by sampling from prior\n",
    "    tf.debugging.assert_positive(x, message=\"gen_gaps first x\")\n",
    "\n",
    "    gap = tf.constant([[0.0]], dtype=tf.float64)\n",
    "    j = 0\n",
    "    ta = tf.TensorArray(tf.float64, size=k + 1)\n",
    "\n",
    "    while tf.less(j, k + 1):\n",
    "        # x' satisfies R(x') - R(u*x) = Z => x' = Rinv(Z + R(u*x))\n",
    "        u = runif()\n",
    "        z = rexp()\n",
    "        u_x = tf.convert_to_tensor([[u * x]])\n",
    "        r_u_x = _R(u_x)  # compute R(u_x)\n",
    "        x = _Rinv(z + r_u_x)  # segment height\n",
    "        # tf.print(x)\n",
    "        # tf.print(z+r_u_x,\"\\n\")\n",
    "        with tf.control_dependencies(\n",
    "            [\n",
    "                tf.debugging.assert_all_finite(x, \"second x\"),\n",
    "                tf.debugging.assert_positive(x, message=\"gen_gaps second x\"),\n",
    "            ]\n",
    "        ):\n",
    "            next_event = rexp() / (x * (mu + rho))\n",
    "            tf.debugging.assert_positive(next_event, message=\"gen_gaps first gap\")\n",
    "            gap += next_event  # length to next event\n",
    "        while runif() < (mu / (mu + rho)) and tf.less(j, k + 1):\n",
    "            ta = ta.write(j, gap)\n",
    "            gap *= 0.0\n",
    "            j += 1\n",
    "            next_event = rexp() / (x * (mu + rho))\n",
    "            tf.debugging.assert_positive(next_event, message=\"gen_gaps second gap\")\n",
    "            gap += next_event  # length to next event\n",
    "\n",
    "    gaps = ta.stack()[1:]  # first obs suffers from inspection paradox?\n",
    "    with tf.control_dependencies(\n",
    "        [\n",
    "            tf.debugging.assert_positive(\n",
    "                gaps, message=\"gaps have non-positive entry\", summarize=100\n",
    "            )\n",
    "        ]\n",
    "    ):\n",
    "        return gaps\n",
    "\n",
    "\n",
    "def R_learned(x, generator):\n",
    "    return R(x, generator.weights[0], generator.weights[1], generator.weights[2])\n",
    "\n",
    "thresh = tf.constant([1e-1], dtype=\"float64\", shape=(1,))\n",
    "\n",
    "def eta(x):\n",
    "    x = tf.cast(x, \"float64\")\n",
    "    one = tf.ones(shape=[1,], dtype=\"float64\",)\n",
    "    return tf.cast(tf.where(x < thresh, 1 / 100, one), \"float64\")\n",
    "\n",
    "def R_real(x):\n",
    "    \"\"\"R_real(x) = integral_0^x eta(t) dt\"\"\"\n",
    "    x = tf.cast(x, \"float64\")\n",
    "    x = tf.reshape(x, (1, tf.size(x)))\n",
    "    tf.debugging.assert_positive(x, message=\"R_real: x>0\")\n",
    "    return tf.cast(\n",
    "        tf.where(x < thresh, x / 100.0, thresh / 100.0 + (x - thresh)), \"float64\"\n",
    "    )\n",
    "    # return x\n",
    "\n",
    "\n",
    "def R_real_inv(y):\n",
    "    y = tf.cast(y, \"float64\")\n",
    "    tf.debugging.assert_positive(y, message=\"R_real: x>0\")\n",
    "    return tf.cast(\n",
    "        tf.where(y < thresh / 100.0, y * 100.0, y - (thresh / 100.0 - thresh)),\n",
    "        \"float64\",\n",
    "    )\n",
    "\n",
    "@tf.function\n",
    "def gen_gaps(\n",
    "    w, v, b, k,\n",
    "):\n",
    "    R_ = lambda x: R(x, w, v, b)\n",
    "    Rinv_ = lambda z: custom_Rinv(z, w, v, b)\n",
    "    return _gen_gaps(k, R_, Rinv_)\n",
    "\n",
    "@tf.function\n",
    "def gen_gaps_real(k: int,):\n",
    "    return _gen_gaps(k, R_real, R_real_inv,)\n",
    "\n",
    "def discriminator_objective(d_x, g_z):\n",
    "    \"\"\"\n",
    "    d_x = real output\n",
    "    g_z = fake output\n",
    "    \"\"\"\n",
    "    real_loss = cross_entropy(\n",
    "        tf.ones_like(d_x), d_x\n",
    "    )  # If we feed the discriminator with real images, we assume they all are the right pictures --> Because of that label == 1\n",
    "    fake_loss = cross_entropy(\n",
    "        tf.zeros_like(g_z), g_z\n",
    "    )  # Each noise we feed in are fakes image --> Because of that labels are 0\n",
    "    total_loss = real_loss + fake_loss\n",
    "\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "ke3db-pVL6Sj"
   },
   "outputs": [],
   "source": [
    "m = tf.keras.metrics.BinaryAccuracy()\n",
    "@tf.function\n",
    "def training_step(discriminator):\n",
    "    with tf.GradientTape() as disc_tape:\n",
    "        # both fake and real seq have shape [Batch_size, seq_len, 1]\n",
    "        fake_seq = tf.reshape(tf.stack([gen_gaps(w, v, b, seq_len) for _ in range(batch_size)]),[batch_size,seq_len,1])\n",
    "        real_seq = tf.reshape(tf.stack([tf.reshape(gen_gaps_real(seq_len), (1, seq_len))\\\n",
    "                                      for _ in range(batch_size)]),[batch_size,seq_len,1])\n",
    "        d_x_true = discriminator(tf.expand_dims(tf.math.log(real_seq),-1))\n",
    "        d_x_fake = discriminator(tf.expand_dims(tf.math.log(fake_seq),-1))\n",
    "        \n",
    "        discriminator_loss = discriminator_objective(d_x_true, d_x_fake)\n",
    "        # Adjusting Gradient of Discriminator\n",
    "        gradients_of_discriminator = disc_tape.gradient(\n",
    "            discriminator_loss, discriminator.trainable_variables\n",
    "        )\n",
    "        discriminator_optimizer.apply_gradients(\n",
    "            zip(gradients_of_discriminator, discriminator.trainable_variables)\n",
    "        )  # Takes a list of gradient and variables pairs\n",
    "    m.reset_states()\n",
    "    m.update_state(tf.ones_like(d_x_true),tf.math.sigmoid(d_x_true))\n",
    "    real_acc = m.result()\n",
    "\n",
    "    m.reset_states()\n",
    "    m.update_state(tf.zeros_like(d_x_fake),tf.math.sigmoid(d_x_fake))\n",
    "    fake_acc = m.result()\n",
    "\n",
    "    return discriminator_loss, real_acc, fake_acc\n",
    "  \n",
    "def training(epoches):\n",
    "    for epoch in range(epoches + 1):\n",
    "        disc_loss,real,fake = training_step(discriminator)\n",
    "        d_loss.append(disc_loss)\n",
    "        real_acc.append(real)\n",
    "        fake_acc.append(fake)\n",
    "        print(\"epoch=%d discriminator_loss=%f real_acc=%f fake_acc=%f\"\n",
    "                % (epoch, disc_loss, real, fake))\n",
    "\n",
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "S9jhuPJK-703"
   },
   "outputs": [],
   "source": [
    "seq_len = 500\n",
    "learning_rate = 0.01\n",
    "batch_size = 100\n",
    "EPOCHES = 500\n",
    "discriminator_optimizer = optimizers.Adam(learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "ec5wj8J8NNHq"
   },
   "outputs": [],
   "source": [
    "#upload weights.csv to colab\n",
    "w,v,b=np.loadtxt('weights.csv',delimiter=',')\n",
    "w = tf.expand_dims(w,-1)\n",
    "v = tf.expand_dims(v,-1)\n",
    "b = tf.expand_dims(b,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "NWDNT8MzOec_",
    "outputId": "6c1e1581-2078-4046-b458-927f33c89271"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "x = tf.math.log(gen_gaps(w, v, b, 1000))\n",
    "y = tf.math.log(gen_gaps_real(1000))\n",
    "plt.hist(x.numpy().reshape(-1),label = 'fake')\n",
    "plt.hist(y.numpy().reshape(-1), alpha=0.4,label='real')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAATQUlEQVR4nO3de4xc5XnH8e9T27AxV9+EjJewDiFcQiE2C12HCJFS7hUQBUfQqrYIkhNKWqe0IjYohSaohaqFBtFA3ODgNJZLamJBuDTGYJQ0CibLJeALtjeuE68F2FhgCsHBhLd/zGt3bO96bzO7Oy/fjzSac97znnOeOTP727PvnJmNlBKSpLL83lAXIEmqPcNdkgpkuEtSgQx3SSqQ4S5JBRo51AUAjB8/PrW0tAx1GZLUUJ555pnXUkoTulo2LMK9paWF9vb2oS5DkhpKRPyqu2UOy0hSgQx3SSqQ4S5JBRoWY+6SNBA7d+6ks7OTHTt2DHUpddHU1ERzczOjRo3q9TqGu6SG19nZySGHHEJLSwsRMdTl1FRKiW3bttHZ2cnkyZN7vZ7DMpIa3o4dOxg3blxxwQ4QEYwbN67Pf5UY7pKKUGKw79Kfx2a4S1KBHHOXVJyWOQ/XdHsbb7moxz533HEHd911F1OnTmXhwoX7LL/33ntpb2/nzjvvrGlt3Wn4cK/1k9gXvXnCJX0wfPOb32TZsmU0NzcPdSmAwzKSNGBf/OIX2bBhAxdccAG33nor06ZNY8qUKXzyk59k7dq1+/R/+OGHmTZtGq+99hpLly5l2rRpTJ06lenTp/PWW2/VpCbDXZIG6O677+bII49k+fLlXH311fzkJz/hueee42tf+xrXX3/9Hn2XLFnCLbfcwiOPPALAzTffzLJly3j22WdpbW3ltttuq0lNDT8sI0nDyfbt25k5cybr168nIti5c+fuZU888QTt7e0sXbqUQw89lIceeojVq1dzxhlnAPDuu+8ybdq0mtRhuEtSDX31q1/l05/+NEuWLGHjxo2cddZZu5cdc8wxbNiwgXXr1tHa2kpKiXPOOYdFixbVvA6HZSSphrZv386kSZOAyhUy1Y4++mjuv/9+ZsyYwapVq2hra+OnP/0pHR0dALz99tusW7euJnU0/Jn7FSMeH5T9LPrd2YOyH0kDN5RXsl133XXMnDmTm2++mYsu2reO448/noULFzJ9+nR++MMfcu+993LFFVfw29/+FqiMwX/sYx8bcB2RUhrwRgaqtbU19fefdcy94doaV9O1rsLdSyGl4WHNmjWccMIJQ11GXXX1GCPimZRSa1f9HZaRpAIZ7pJUIMNdkgpkuEtSgQx3SSqQ4S5JBWr469wlaR/t36nt9lqvrO329tLS0kJ7ezvjx4+v2TY9c5ekGkop8f777w91GYa7JA3Uxo0bOe6445gxYwYnnXQSX//61znttNM4+eSTufHGG3f3u/TSSzn11FP5+Mc/zrx58+pak8MyklQD69evZ8GCBbz55pssXryYp59+mpQSF198MT/+8Y8588wzmT9/PmPHjuWdd97htNNO47Of/Szjxo2rSz2euUtSDRx99NG0tbWxdOlSli5dypQpU5g6dSovvfQS69evByr/iu+UU06hra2NTZs27W6vB8/cJakGDjroIKAy5j537ly+8IUv7LH8ySefZNmyZfzsZz9j9OjRnHXWWezYsaNu9XjmLkk1dN555zF//vzd/y5v8+bNbNmyhe3btzNmzBhGjx7NSy+9xFNPPVXXOjxzl1SeOl+6uD/nnnsua9as2f0flQ4++GC+973vcf7553P33XdzwgkncNxxx9HW1lbXOgx3SRqglpYWVq5cuXt+9uzZzJ49e59+jz76aJfrb9y4seY1OSwjSQUy3CWpQL0K94j4q4hYFRErI2JRRDRFxOSIWBERHRFxX0QckPsemOc78vKWej4ASYLKVSql6s9j6zHcI2IS8JdAa0rpJGAEcDlwK3B7SumjwOvAVXmVq4DXc/vtuZ8k1U1TUxPbtm0rMuBTSmzbto2mpqY+rdfbN1RHAh+KiJ3AaOBl4A+BP8nLFwA3AXcBl+RpgMXAnRERqcSjLmlYaG5uprOzk61btw51KXXR1NREc3Nzn9bpMdxTSpsj4p+AXwPvAEuBZ4A3Ukrv5W6dwKQ8PQnYlNd9LyK2A+OA16q3GxGzgFkAH/7wh/tUtCRVGzVqFJMnTx7qMoaV3gzLjKFyNj4ZOBI4CDh/oDtOKc1LKbWmlFonTJgw0M1Jkqr05g3VPwL+J6W0NaW0E/gBcAZweETsOvNvBjbn6c3AUQB5+WHAtppWLUnar96E+6+BtogYHREBnA2sBpYDl+U+M4EH8vSDeZ68/AnH2yVpcPUY7imlFVTeGH0WeDGvMw/4CnBtRHRQGVO/J69yDzAut18LzKlD3ZKk/ejV1TIppRuBG/dq3gCc3kXfHcD0gZcmSeovP6EqSQUy3CWpQIa7JBXIcJekAhnuklQgw12SCmS4S1KBDHdJKpDhLkkFMtwlqUCGuyQVyHCXpAIZ7pJUIMNdkgpkuEtSgQx3SSqQ4S5JBTLcJalAhrskFchwl6QCGe6SVCDDXZIKZLhLUoEMd0kqkOEuSQUy3CWpQIa7JBXIcJekAhnuklQgw12SCmS4S1KBDHdJKpDhLkkFMtwlqUCGuyQVqFfhHhGHR8TiiHgpItZExLSIGBsRj0XE+nw/JveNiLgjIjoi4oWImFrfhyBJ2ltvz9y/AfxXSul44BRgDTAHeDyldCzweJ4HuAA4Nt9mAXfVtGJJUo96DPeIOAw4E7gHIKX0bkrpDeASYEHutgC4NE9fAnw3VTwFHB4RE2teuSSpW705c58MbAW+ExHPRcS3I+Ig4IiU0su5zyvAEXl6ErCpav3O3LaHiJgVEe0R0b5169b+PwJJ0j56E+4jganAXSmlKcDb/P8QDAAppQSkvuw4pTQvpdSaUmqdMGFCX1aVJPWgN+HeCXSmlFbk+cVUwv7VXcMt+X5LXr4ZOKpq/ebcJkkaJD2Ge0rpFWBTRByXm84GVgMPAjNz20zggTz9IDAjXzXTBmyvGr6RJA2Ckb3s9xfAwog4ANgAXEnlF8P3I+Iq4FfA53LfR4ALgQ7gN7mvJGkQ9SrcU0rPA61dLDq7i74JuGaAdUmSBsBPqEpSgQx3SSqQ4S5JBTLcJalAhrskFchwl6QCGe6SVCDDXZIKZLhLUoEMd0kqkOEuSQUy3CWpQIa7JBXIcJekAhnuklQgw12SCmS4S1KBDHdJKpDhLkkFMtwlqUCGuyQVyHCXpAIZ7pJUIMNdkgpkuEtSgQx3SSqQ4S5JBTLcJalAhrskFchwl6QCGe6SVCDDXZIKZLhLUoEMd0kqkOEuSQUy3CWpQL0O94gYERHPRcRDeX5yRKyIiI6IuC8iDsjtB+b5jry8pT6lS5K605cz99nAmqr5W4HbU0ofBV4HrsrtVwGv5/bbcz9J0iDqVbhHRDNwEfDtPB/AHwKLc5cFwKV5+pI8T15+du4vSRokvT1z/xfgOuD9PD8OeCOl9F6e7wQm5elJwCaAvHx77r+HiJgVEe0R0b5169Z+li9J6kqP4R4RfwxsSSk9U8sdp5TmpZRaU0qtEyZMqOWmJekDb2Qv+pwBXBwRFwJNwKHAN4DDI2JkPjtvBjbn/puBo4DOiBgJHAZsq3nlkqRu9XjmnlKam1JqTim1AJcDT6SU/hRYDlyWu80EHsjTD+Z58vInUkqpplVLkvZrINe5fwW4NiI6qIyp35Pb7wHG5fZrgTkDK1GS1Fe9GZbZLaX0JPBknt4AnN5Fnx3A9BrUJknqJz+hKkkFMtwlqUCGuyQVyHCXpAIZ7pJUIMNdkgpkuEtSgQx3SSqQ4S5JBTLcJalAhrskFchwl6QCGe6SVCDDXZIKZLhLUoEMd0kqkOEuSQUy3CWpQIa7JBXIcJekAhnuklQgw12SCmS4S1KBDHdJKpDhLkkFMtwlqUCGuyQVyHCXpAIZ7pJUIMNdkgpkuEtSgQx3SSqQ4S5JBTLcJalAhrskFchwl6QC9RjuEXFURCyPiNURsSoiZuf2sRHxWESsz/djcntExB0R0RERL0TE1Ho/CEnSnnpz5v4e8NcppROBNuCaiDgRmAM8nlI6Fng8zwNcABybb7OAu2petSRpv3oM95TSyymlZ/P0/wJrgEnAJcCC3G0BcGmevgT4bqp4Cjg8IibWvHJJUrf6NOYeES3AFGAFcERK6eW86BXgiDw9CdhUtVpnbtt7W7Mioj0i2rdu3drHsiVJ+9PrcI+Ig4H7gS+nlN6sXpZSSkDqy45TSvNSSq0ppdYJEyb0ZVVJUg96Fe4RMYpKsC9MKf0gN7+6a7gl32/J7ZuBo6pWb85tkqRB0purZQK4B1iTUrqtatGDwMw8PRN4oKp9Rr5qpg3YXjV8I0kaBCN70ecM4M+AFyPi+dx2PXAL8P2IuAr4FfC5vOwR4EKgA/gNcGVNK5Yk9ajHcE8p/TcQ3Sw+u4v+CbhmgHVJkgbAT6hKUoEMd0kqkOEuSQUy3CWpQIa7JBXIcJekAhnuklQgw12SCmS4S1KBDHdJKpDhLkkFMtwlqUCGuyQVyHCXpAIZ7pJUIMNdkgpkuEtSgQx3SSqQ4S5JBTLcJalAhrskFchwl6QCGe6SVKCRQ11Ao7hixOP7NrZvqf2OWq+s/TYlfeB45i5JBTLcJalAhrskFcgx9wGYu+TFmm9z0eKHe+yz8ZaLar5fSWXxzF2SCmS4S1KBDHdJKpDhLkkFMtwlqUCGuyQVyHCXpAJ5nfsw0+V32OytFt9p43fYSEWrS7hHxPnAN4ARwLdTSrfUYz8fVLX48FRvPizVFT9AJTWGmod7RIwA/hU4B+gEfh4RD6aUVtd6X+q/Xv2F0IW5N/R9vUW/O7tf+6rmLxWpb+px5n460JFS2gAQEf8BXAIY7h9Q/f1FUq0/v1Rq4R8+8/tDsl/AoTMNSD3CfRKwqWq+E/iDvTtFxCxgVp59KyLW9nN/44HX+rnucGD9Q6fH2m/5+0GqpEuf76lDIx97aOz6h0vtR3e3YMjeUE0pzQPmDXQ7EdGeUmqtQUlDwvqHTiPXDtY/lBqh9npcCrkZOKpqvjm3SZIGST3C/efAsRExOSIOAC4HHqzDfiRJ3aj5sExK6b2I+BLwIyqXQs5PKa2q9X6qDHhoZ4hZ/9Bp5NrB+ofSsK89UkpDXYMkqcb8+gFJKpDhLkkFauhwj4jzI2JtRHRExJwhrmVjRLwYEc9HRHtuGxsRj0XE+nw/JrdHRNyR634hIqZWbWdm7r8+ImZWtZ+at9+R140B1js/IrZExMqqtrrX290+alT/TRGxOT8Hz0fEhVXL5uZa1kbEeVXtXb6G8gUBK3L7ffniACLiwDzfkZe39KP2oyJieUSsjohVETF7f8dmuB3//dQ/7I9/RDRFxNMR8Ytc+9/1d3+1ekx1k1JqyBuVN2t/CXwEOAD4BXDiENazERi/V9s/AnPy9Bzg1jx9IfAoEEAbsCK3jwU25PsxeXpMXvZ07ht53QsGWO+ZwFRg5WDW290+alT/TcDfdNH3xPz6OBCYnF83I/b3GgK+D1yep+8Grs7Tfw7cnacvB+7rR+0Tgal5+hBgXa6xIY7/fuof9sc/H4+D8/QoYEU+Tn3aXy0fU71uQxKENSkcpgE/qpqfC8wdwno2sm+4rwUm5umJwNo8/S3gir37AVcA36pq/1Zumwi8VNW+R78B1NzCnuFY93q720eN6r+JrsNlj9cGlSu5pnX3GsoB8Bowcu/X2q518/TI3C8G+Dw8QOW7mBrq+HdRf0Mdf2A08CyVT9D3aX+1fEz1ujXysExXX3MwaYhqAUjA0oh4JipfrQBwRErp5Tz9CnBEnu6u9v21d3bRXmuDUW93+6iVL+Whi/lVQw59rX8c8EZK6b0u6t+9Tl6+Pffvl/xn/hQqZ5ANd/z3qh8a4PhHxIiIeB7YAjxG5Uy7r/ur5WOqi0YO9+HmUymlqcAFwDURcWb1wlT5dd0w150ORr112MddwDHAJ4CXgX+u4bZrLiIOBu4HvpxSerN6WSMc/y7qb4jjn1L6XUrpE1Q+PX86cPwQl1QXjRzuw+prDlJKm/P9FmAJlRfNqxExESDf7/ovG93Vvr/25i7aa20w6u1uHwOWUno1/+C+D/wbleegP/VvAw6PiJF7te+xrbz8sNy/TyJiFJVgXJhS+kFubpjj31X9jXT8c71vAMupDJH0dX+1fEx10cjhPmy+5iAiDoqIQ3ZNA+cCK3M9u65gmEllbJLcPiNfBdEGbM9/Kv8IODcixuQ/ac+lMi73MvBmRLTlqx5mVG2rlgaj3u72MWC7Qiv7DJXnYNc+L89XPkwGjqXyhmOXr6F8RrscuKybY7Gr/suAJ3L/vtQZwD3AmpTSbVWLGuL4d1d/Ixz/iJgQEYfn6Q9Rea9gTT/2V8vHVB/1HNCv943KVQTrqIyZ3TCEdXyEyrvivwBW7aqFyjjb48B6YBkwNrcHlX9o8kvgRaC1alufBzry7cqq9lYqPyy/BO5k4G/iLaLyp/NOKuN/Vw1Gvd3to0b1/3uu7wUqP3wTq/rfkGtZS9WVRt29hvJz+nR+XP8JHJjbm/J8R17+kX7U/ikqwyEvAM/n24WNcvz3U/+wP/7AycBzucaVwN/2d3+1ekz1uvn1A5JUoEYelpEkdcNwl6QCGe6SVCDDXZIKZLhLUoEMd0kqkOEuSQX6P0HBF8T44uJbAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = gen_gaps(w, v, b, 1000)\n",
    "y = gen_gaps_real(1000)\n",
    "plt.hist(x.numpy().reshape(-1),label = 'fake')\n",
    "plt.hist(y.numpy().reshape(-1), alpha=0.4,label='real')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 503
    },
    "id": "LN8jwzyXLxoW",
    "outputId": "d0b2b7c7-d9f1-42f8-d287-842ec8fce0e5",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"discriminator\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 500, 256)          1280      \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 500, 256)          1024      \n",
      "_________________________________________________________________\n",
      "re_lu (ReLU)                 (None, 500, 256)          0         \n",
      "_________________________________________________________________\n",
      "simple_rnn (SimpleRNN)       (None, 100)               35700     \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 38,105\n",
      "Trainable params: 37,593\n",
      "Non-trainable params: 512\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "discriminator = Sequential(\n",
    "    [\n",
    "     Input(shape=(seq_len,1)),\n",
    "     Conv1D(filters=256, kernel_size=4,padding='same'),\n",
    "     BatchNormalization(),\n",
    "     ReLU(),\n",
    "     SimpleRNN(100,return_sequences=False),\n",
    "     Flatten(),\n",
    "     Dense(1)\n",
    "    ],\n",
    "    name=\"discriminator\",\n",
    ")\n",
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "3XQB77QPNFVt",
    "outputId": "ea604227-c9bc-4685-8265-ad60c7e63bcd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=0 discriminator_loss=1.679668 real_acc=0.000000 fake_acc=1.000000\n",
      "epoch=1 discriminator_loss=6.734287 real_acc=1.000000 fake_acc=0.000000\n",
      "epoch=2 discriminator_loss=2.690679 real_acc=1.000000 fake_acc=0.000000\n",
      "epoch=3 discriminator_loss=1.524225 real_acc=0.000000 fake_acc=1.000000\n",
      "epoch=4 discriminator_loss=1.648585 real_acc=0.000000 fake_acc=1.000000\n",
      "epoch=5 discriminator_loss=1.468439 real_acc=0.000000 fake_acc=1.000000\n",
      "epoch=6 discriminator_loss=1.403639 real_acc=0.040000 fake_acc=0.950000\n",
      "epoch=7 discriminator_loss=1.401582 real_acc=0.990000 fake_acc=0.020000\n",
      "epoch=8 discriminator_loss=1.407378 real_acc=1.000000 fake_acc=0.000000\n",
      "epoch=9 discriminator_loss=1.416515 real_acc=1.000000 fake_acc=0.000000\n",
      "epoch=10 discriminator_loss=1.400934 real_acc=1.000000 fake_acc=0.000000\n",
      "epoch=11 discriminator_loss=1.389228 real_acc=1.000000 fake_acc=0.000000\n",
      "epoch=12 discriminator_loss=1.387469 real_acc=0.000000 fake_acc=1.000000\n",
      "epoch=13 discriminator_loss=1.393461 real_acc=0.000000 fake_acc=1.000000\n",
      "epoch=14 discriminator_loss=1.401105 real_acc=0.000000 fake_acc=1.000000\n",
      "epoch=15 discriminator_loss=1.400656 real_acc=0.000000 fake_acc=1.000000\n",
      "epoch=16 discriminator_loss=1.394650 real_acc=0.000000 fake_acc=1.000000\n",
      "epoch=17 discriminator_loss=1.389421 real_acc=0.000000 fake_acc=1.000000\n",
      "epoch=18 discriminator_loss=1.386115 real_acc=0.300000 fake_acc=0.700000\n",
      "epoch=19 discriminator_loss=1.388023 real_acc=1.000000 fake_acc=0.000000\n",
      "epoch=20 discriminator_loss=1.390999 real_acc=1.000000 fake_acc=0.000000\n",
      "epoch=21 discriminator_loss=1.392789 real_acc=1.000000 fake_acc=0.000000\n",
      "epoch=22 discriminator_loss=1.391560 real_acc=1.000000 fake_acc=0.000000\n",
      "epoch=23 discriminator_loss=1.388801 real_acc=1.000000 fake_acc=0.000000\n",
      "epoch=24 discriminator_loss=1.386568 real_acc=1.000000 fake_acc=0.000000\n",
      "epoch=25 discriminator_loss=1.386456 real_acc=0.000000 fake_acc=1.000000\n",
      "epoch=26 discriminator_loss=1.388064 real_acc=0.000000 fake_acc=1.000000\n",
      "epoch=27 discriminator_loss=1.389251 real_acc=0.000000 fake_acc=1.000000\n",
      "epoch=28 discriminator_loss=1.389181 real_acc=0.000000 fake_acc=1.000000\n",
      "epoch=29 discriminator_loss=1.388035 real_acc=0.000000 fake_acc=1.000000\n",
      "epoch=30 discriminator_loss=1.386395 real_acc=0.000000 fake_acc=1.000000\n",
      "epoch=31 discriminator_loss=1.386303 real_acc=1.000000 fake_acc=0.000000\n",
      "epoch=32 discriminator_loss=1.386858 real_acc=1.000000 fake_acc=0.000000\n",
      "epoch=33 discriminator_loss=1.387417 real_acc=1.000000 fake_acc=0.000000\n",
      "epoch=34 discriminator_loss=1.388126 real_acc=1.000000 fake_acc=0.000000\n",
      "epoch=35 discriminator_loss=1.386756 real_acc=1.000000 fake_acc=0.000000\n",
      "epoch=36 discriminator_loss=1.386446 real_acc=1.000000 fake_acc=0.000000\n",
      "epoch=37 discriminator_loss=1.385592 real_acc=0.070000 fake_acc=0.960000\n",
      "epoch=38 discriminator_loss=1.386491 real_acc=0.000000 fake_acc=1.000000\n",
      "epoch=39 discriminator_loss=1.386452 real_acc=0.000000 fake_acc=1.000000\n",
      "epoch=40 discriminator_loss=1.386571 real_acc=0.000000 fake_acc=1.000000\n",
      "epoch=41 discriminator_loss=1.387713 real_acc=0.000000 fake_acc=1.000000\n",
      "epoch=42 discriminator_loss=1.386196 real_acc=0.050000 fake_acc=0.930000\n",
      "epoch=43 discriminator_loss=1.386252 real_acc=0.980000 fake_acc=0.030000\n",
      "epoch=44 discriminator_loss=1.385529 real_acc=1.000000 fake_acc=0.010000\n",
      "epoch=45 discriminator_loss=1.386218 real_acc=1.000000 fake_acc=0.000000\n",
      "epoch=46 discriminator_loss=1.385490 real_acc=1.000000 fake_acc=0.000000\n",
      "epoch=47 discriminator_loss=1.385488 real_acc=0.870000 fake_acc=0.110000\n",
      "epoch=48 discriminator_loss=1.384409 real_acc=0.300000 fake_acc=0.820000\n",
      "epoch=49 discriminator_loss=1.386240 real_acc=0.040000 fake_acc=0.980000\n",
      "epoch=50 discriminator_loss=1.387477 real_acc=0.020000 fake_acc=0.960000\n",
      "epoch=51 discriminator_loss=1.387874 real_acc=0.030000 fake_acc=0.950000\n",
      "epoch=52 discriminator_loss=1.385709 real_acc=0.190000 fake_acc=0.770000\n",
      "epoch=53 discriminator_loss=1.386193 real_acc=0.620000 fake_acc=0.390000\n",
      "epoch=54 discriminator_loss=1.387319 real_acc=0.970000 fake_acc=0.040000\n",
      "epoch=55 discriminator_loss=1.383132 real_acc=1.000000 fake_acc=0.000000\n",
      "epoch=56 discriminator_loss=1.386764 real_acc=0.970000 fake_acc=0.030000\n",
      "epoch=57 discriminator_loss=1.384256 real_acc=0.660000 fake_acc=0.440000\n",
      "epoch=58 discriminator_loss=1.383840 real_acc=0.310000 fake_acc=0.740000\n",
      "epoch=59 discriminator_loss=1.385580 real_acc=0.100000 fake_acc=0.920000\n",
      "epoch=60 discriminator_loss=1.385315 real_acc=0.090000 fake_acc=0.860000\n",
      "epoch=61 discriminator_loss=1.384086 real_acc=0.340000 fake_acc=0.740000\n",
      "epoch=62 discriminator_loss=1.384932 real_acc=0.570000 fake_acc=0.480000\n",
      "epoch=63 discriminator_loss=1.384490 real_acc=0.790000 fake_acc=0.270000\n",
      "epoch=64 discriminator_loss=1.388527 real_acc=0.760000 fake_acc=0.220000\n",
      "epoch=65 discriminator_loss=1.385425 real_acc=0.570000 fake_acc=0.490000\n",
      "epoch=66 discriminator_loss=1.385458 real_acc=0.370000 fake_acc=0.620000\n",
      "epoch=67 discriminator_loss=1.383204 real_acc=0.320000 fake_acc=0.780000\n",
      "epoch=68 discriminator_loss=1.384857 real_acc=0.170000 fake_acc=0.840000\n",
      "epoch=69 discriminator_loss=1.385942 real_acc=0.320000 fake_acc=0.730000\n",
      "epoch=70 discriminator_loss=1.385393 real_acc=0.480000 fake_acc=0.550000\n",
      "epoch=71 discriminator_loss=1.385391 real_acc=0.780000 fake_acc=0.300000\n",
      "epoch=72 discriminator_loss=1.390252 real_acc=0.860000 fake_acc=0.150000\n",
      "epoch=73 discriminator_loss=1.385040 real_acc=0.910000 fake_acc=0.140000\n",
      "epoch=74 discriminator_loss=1.383359 real_acc=0.710000 fake_acc=0.350000\n",
      "epoch=75 discriminator_loss=1.384883 real_acc=0.380000 fake_acc=0.680000\n",
      "epoch=76 discriminator_loss=1.385375 real_acc=0.280000 fake_acc=0.700000\n",
      "epoch=77 discriminator_loss=1.385176 real_acc=0.390000 fake_acc=0.620000\n",
      "epoch=78 discriminator_loss=1.385619 real_acc=0.520000 fake_acc=0.490000\n",
      "epoch=79 discriminator_loss=1.385470 real_acc=0.680000 fake_acc=0.330000\n",
      "epoch=80 discriminator_loss=1.387716 real_acc=0.680000 fake_acc=0.290000\n",
      "epoch=81 discriminator_loss=1.386579 real_acc=0.770000 fake_acc=0.310000\n",
      "epoch=82 discriminator_loss=1.385296 real_acc=0.780000 fake_acc=0.390000\n",
      "epoch=83 discriminator_loss=1.386265 real_acc=0.540000 fake_acc=0.520000\n",
      "epoch=84 discriminator_loss=1.386161 real_acc=0.240000 fake_acc=0.710000\n",
      "epoch=85 discriminator_loss=1.384352 real_acc=0.160000 fake_acc=0.840000\n",
      "epoch=86 discriminator_loss=1.387053 real_acc=0.130000 fake_acc=0.890000\n",
      "epoch=87 discriminator_loss=1.385531 real_acc=0.320000 fake_acc=0.760000\n",
      "epoch=88 discriminator_loss=1.385711 real_acc=0.560000 fake_acc=0.450000\n",
      "epoch=89 discriminator_loss=1.385100 real_acc=0.730000 fake_acc=0.320000\n",
      "epoch=90 discriminator_loss=1.385878 real_acc=0.530000 fake_acc=0.470000\n",
      "epoch=91 discriminator_loss=1.381803 real_acc=0.260000 fake_acc=0.820000\n",
      "epoch=92 discriminator_loss=1.387420 real_acc=0.140000 fake_acc=0.860000\n",
      "epoch=93 discriminator_loss=1.384439 real_acc=0.270000 fake_acc=0.800000\n",
      "epoch=94 discriminator_loss=1.384287 real_acc=0.490000 fake_acc=0.530000\n",
      "epoch=95 discriminator_loss=1.384170 real_acc=0.680000 fake_acc=0.380000\n",
      "epoch=96 discriminator_loss=1.389184 real_acc=0.740000 fake_acc=0.220000\n",
      "epoch=97 discriminator_loss=1.385745 real_acc=0.680000 fake_acc=0.300000\n",
      "epoch=98 discriminator_loss=1.385044 real_acc=0.320000 fake_acc=0.750000\n",
      "epoch=99 discriminator_loss=1.387968 real_acc=0.150000 fake_acc=0.830000\n"
     ]
    }
   ],
   "source": [
    "d_loss = []\n",
    "real_acc = []\n",
    "fake_acc = []\n",
    "training(EPOCHES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 461
    },
    "id": "Ud8R_l_Gae02",
    "outputId": "cbfbfcf8-e5e9-4ca9-ae9a-0cda58f96f0c"
   },
   "outputs": [],
   "source": [
    "B = 20\n",
    "W = np.hamming(B)\n",
    "W /= W.sum()\n",
    "plt.figure(figsize = (21,8))\n",
    "plt.plot(range(len(real_acc)),np.convolve(real_acc, W, mode='same'),label='real')\n",
    "plt.plot(range(len(real_acc)),np.convolve(fake_acc, W, mode='same'),label='fake')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "train_D.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
