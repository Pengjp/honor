{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "rEP8Ti9V-1B4"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import optimizers, layers, Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, LeakyReLU,Conv1D,Dropout,MaxPooling1D,SimpleRNN,LocallyConnected1D\n",
    "from tensorflow.keras.layers import Flatten,ReLU, BatchNormalization,GlobalAveragePooling1D\n",
    "import numpy as np\n",
    "\n",
    "def runif():\n",
    "    return tf.random.uniform([1], dtype=tf.float64)[0]\n",
    "    # return tf.constant(.8, tf.float32)\n",
    "\n",
    "def rexp():\n",
    "    return -tf.math.log(runif())\n",
    "\n",
    "\n",
    "def exprelu(x):\n",
    "    return tf.where(x > 0, tf.math.expm1(x), tf.zeros_like(x))\n",
    "\n",
    "def reloid(x):\n",
    "    \"(sigma(x[1]), ..., sigma(x[-2]), relu(x[-1])\"\n",
    "    return tf.concat([tf.nn.sigmoid(x[:-1]), tf.math.exp(x[-1:])], axis=0)\n",
    "\n",
    "def reloid_derivative(x):\n",
    "    return tf.concat(\n",
    "        [\n",
    "            tf.nn.sigmoid(x[:-1])\n",
    "            * (1 - tf.nn.sigmoid(x[:-1])),  # derivative of sigmoid\n",
    "            tf.math.exp(x[-1:]),\n",
    "        ],\n",
    "        axis=0,\n",
    "    )\n",
    "\n",
    "def S(x, w, v, b):\n",
    "    \"\"\"\n",
    "    x: scalar\n",
    "    w, v, b: (3, H)\n",
    "    \"\"\"\n",
    "    x = tf.convert_to_tensor(x, dtype=\"float64\")\n",
    "    # tf.debugging.assert_positive(x, message=\"R: x>0\")\n",
    "    exp_w_v = tf.math.exp([w, v])\n",
    "    ew = exp_w_v[0]\n",
    "    ev = exp_w_v[1]\n",
    "    # b = tf.math.sigmoid(b) # try this  # JT - bug. was sigb\n",
    "    ew = tf.concat([ew[:-1], tf.ones_like(ew[-1:]),], axis=0,)\n",
    "    x = tf.reshape(x, (1, 1))\n",
    "    return tf.transpose(ev) @ reloid(ew @ x + b)\n",
    "\n",
    "@tf.function\n",
    "def R(x, w, v, b):\n",
    "    return S(tf.math.log(x), w, v, b)\n",
    "\n",
    "@tf.function\n",
    "def Rinv(y, w, v, b):\n",
    "    y = tf.convert_to_tensor(y, dtype=\"float64\")\n",
    "    # y = tf.reshape(y, (-1,))[0]\n",
    "    # as x -> oo, R is asymyptotic to exp(v[-1] + w[-1]) x\n",
    "    # fixme: calculate this exactly.\n",
    "    x_left = tf.convert_to_tensor([[0.0]], tf.float64)\n",
    "    x_right = tf.convert_to_tensor([[1e8]], tf.float64)\n",
    "    # tf.print((x_left, x_right))\n",
    "    # tf.print(\"y\", y)\n",
    "    # tf.print('y',y)\n",
    "    # tf.debugging.assert_greater(R(x_right, w, v, b), y, message=\"R(x_right)>y inv\")\n",
    "\n",
    "    def cond(xl, xr):\n",
    "        # tf.print(xl, xr)\n",
    "        xi = (xl + xr) / 2.0\n",
    "        yi = R(xi, w, v, b)[0, 0]\n",
    "        return abs(y - yi) > 1e-6\n",
    "\n",
    "    def body(xl, xr):\n",
    "        xi = (xl + xr) / 2.0\n",
    "        yi = R(xi, w, v, b)[0, 0]\n",
    "        left = tf.cast(yi < y, dtype=\"float64\")\n",
    "        xl = left * xi + (1.0 - left) * xl\n",
    "        xr = (1.0 - left) * xi + left * xr\n",
    "        return (xl, xr)\n",
    "        # print(y, x_i, y_i)\n",
    "\n",
    "    xl, xr = tf.while_loop(cond, body, (x_left, x_right))\n",
    "    return (xl + xr) / 2.0\n",
    "\n",
    "@tf.custom_gradient\n",
    "def custom_Rinv(y, w, v, b):\n",
    "    y = tf.convert_to_tensor(y, dtype=\"float64\")\n",
    "    x = Rinv(y, w, v, b)\n",
    "    with tf.GradientTape() as g:\n",
    "        g.watch([x, w, v, b])\n",
    "        y = R(x, w, v, b)\n",
    "    dR_dw, dR_dv, dR_db, dR_dx = g.gradient(y, [w, v, b, x])\n",
    "\n",
    "    def grad(dx):\n",
    "        return dx / dR_dx, -dx * dR_dw / dR_dx, -dx * dR_dv / dR_dx, -dx * dR_db / dR_dx\n",
    "\n",
    "    return x, grad\n",
    "\n",
    "mu = 1e-4\n",
    "rho = 1e-5\n",
    "\n",
    "def _gen_gaps(k: int, _R, _Rinv,) -> tf.Tensor:\n",
    "    \"\"\"Return k gaps sampled from genetic distribution with rate function eta.\"\"\"\n",
    "    z = tf.convert_to_tensor([[rexp()]])\n",
    "    x = _Rinv(z)  # initialize x by sampling from prior\n",
    "    tf.debugging.assert_positive(x, message=\"gen_gaps first x\")\n",
    "\n",
    "    gap = tf.constant([[0.0]], dtype=tf.float64)\n",
    "    j = 0\n",
    "    ta = tf.TensorArray(tf.float64, size=k + 1)\n",
    "\n",
    "    while tf.less(j, k + 1):\n",
    "        # x' satisfies R(x') - R(u*x) = Z => x' = Rinv(Z + R(u*x))\n",
    "        u = runif()\n",
    "        z = rexp()\n",
    "        u_x = tf.convert_to_tensor([[u * x]])\n",
    "        r_u_x = _R(u_x)  # compute R(u_x)\n",
    "        x = _Rinv(z + r_u_x)  # segment height\n",
    "        # tf.print(x)\n",
    "        # tf.print(z+r_u_x,\"\\n\")\n",
    "        with tf.control_dependencies(\n",
    "            [\n",
    "                tf.debugging.assert_all_finite(x, \"second x\"),\n",
    "                tf.debugging.assert_positive(x, message=\"gen_gaps second x\"),\n",
    "            ]\n",
    "        ):\n",
    "            next_event = rexp() / (x * (mu + rho))\n",
    "            tf.debugging.assert_positive(next_event, message=\"gen_gaps first gap\")\n",
    "            gap += next_event  # length to next event\n",
    "        while runif() < (mu / (mu + rho)) and tf.less(j, k + 1):\n",
    "            ta = ta.write(j, gap)\n",
    "            gap *= 0.0\n",
    "            j += 1\n",
    "            next_event = rexp() / (x * (mu + rho))\n",
    "            tf.debugging.assert_positive(next_event, message=\"gen_gaps second gap\")\n",
    "            gap += next_event  # length to next event\n",
    "\n",
    "    gaps = ta.stack()[1:]  # first obs suffers from inspection paradox?\n",
    "    with tf.control_dependencies(\n",
    "        [\n",
    "            tf.debugging.assert_positive(\n",
    "                gaps, message=\"gaps have non-positive entry\", summarize=100\n",
    "            )\n",
    "        ]\n",
    "    ):\n",
    "        return gaps\n",
    "\n",
    "\n",
    "def R_learned(x, generator):\n",
    "    return R(x, generator.weights[0], generator.weights[1], generator.weights[2])\n",
    "\n",
    "thresh = tf.constant([1e-1], dtype=\"float64\", shape=(1,))\n",
    "\n",
    "def eta(x):\n",
    "    x = tf.cast(x, \"float64\")\n",
    "    one = tf.ones(shape=[1,], dtype=\"float64\",)\n",
    "    return tf.cast(tf.where(x < thresh, 1 / 100, one), \"float64\")\n",
    "\n",
    "def R_real(x):\n",
    "    \"\"\"R_real(x) = integral_0^x eta(t) dt\"\"\"\n",
    "    x = tf.cast(x, \"float64\")\n",
    "    x = tf.reshape(x, (1, tf.size(x)))\n",
    "    tf.debugging.assert_positive(x, message=\"R_real: x>0\")\n",
    "    return tf.cast(\n",
    "        tf.where(x < thresh, x / 100.0, thresh / 100.0 + (x - thresh)), \"float64\"\n",
    "    )\n",
    "    # return x\n",
    "\n",
    "\n",
    "def R_real_inv(y):\n",
    "    y = tf.cast(y, \"float64\")\n",
    "    tf.debugging.assert_positive(y, message=\"R_real: x>0\")\n",
    "    return tf.cast(\n",
    "        tf.where(y < thresh / 100.0, y * 100.0, y - (thresh / 100.0 - thresh)),\n",
    "        \"float64\",\n",
    "    )\n",
    "\n",
    "@tf.function\n",
    "def gen_gaps(\n",
    "    w, v, b, k,\n",
    "):\n",
    "    R_ = lambda x: R(x, w, v, b)\n",
    "    Rinv_ = lambda z: custom_Rinv(z, w, v, b)\n",
    "    return _gen_gaps(k, R_, Rinv_)\n",
    "\n",
    "@tf.function\n",
    "def gen_gaps_real(k: int,):\n",
    "    return _gen_gaps(k, R_real, R_real_inv,)\n",
    "\n",
    "def discriminator_objective(d_x, g_z):\n",
    "    \"\"\"\n",
    "    d_x = real output\n",
    "    g_z = fake output\n",
    "    \"\"\"\n",
    "    real_loss = cross_entropy(\n",
    "        tf.ones_like(d_x), d_x\n",
    "    )  # If we feed the discriminator with real images, we assume they all are the right pictures --> Because of that label == 1\n",
    "    fake_loss = cross_entropy(\n",
    "        tf.zeros_like(g_z), g_z\n",
    "    )  # Each noise we feed in are fakes image --> Because of that labels are 0\n",
    "    total_loss = real_loss + fake_loss\n",
    "\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "ke3db-pVL6Sj"
   },
   "outputs": [],
   "source": [
    "m = tf.keras.metrics.BinaryAccuracy()\n",
    "@tf.function\n",
    "def training_step(discriminator):\n",
    "    with tf.GradientTape() as disc_tape:\n",
    "        # both fake and real seq have shape [Batch_size, seq_len, 1]\n",
    "        fake_seq = tf.reshape(tf.stack([gen_gaps(w, v, b, seq_len) for _ in range(batch_size)]),[batch_size,seq_len,1])\n",
    "        real_seq = tf.reshape(tf.stack([tf.reshape(gen_gaps_real(seq_len), (1, seq_len))\\\n",
    "                                      for _ in range(batch_size)]),[batch_size,seq_len,1])\n",
    "        d_x_true = discriminator(tf.expand_dims(tf.math.log(real_seq),-1))\n",
    "        d_x_fake = discriminator(tf.expand_dims(tf.math.log(fake_seq),-1))\n",
    "        \n",
    "        discriminator_loss = discriminator_objective(d_x_true, d_x_fake)\n",
    "        # Adjusting Gradient of Discriminator\n",
    "        gradients_of_discriminator = disc_tape.gradient(\n",
    "            discriminator_loss, discriminator.trainable_variables\n",
    "        )\n",
    "        discriminator_optimizer.apply_gradients(\n",
    "            zip(gradients_of_discriminator, discriminator.trainable_variables)\n",
    "        )  # Takes a list of gradient and variables pairs\n",
    "    m.reset_states()\n",
    "    m.update_state(tf.ones_like(d_x_true),tf.math.sigmoid(d_x_true))\n",
    "    real_acc = m.result()\n",
    "\n",
    "    m.reset_states()\n",
    "    m.update_state(tf.zeros_like(d_x_fake),tf.math.sigmoid(d_x_fake))\n",
    "    fake_acc = m.result()\n",
    "\n",
    "    return discriminator_loss, real_acc, fake_acc\n",
    "  \n",
    "def training(epoches):\n",
    "    for epoch in range(epoches + 1):\n",
    "        disc_loss,real,fake = training_step(discriminator)\n",
    "        d_loss.append(disc_loss)\n",
    "        real_acc.append(real)\n",
    "        fake_acc.append(fake)\n",
    "        print(\"epoch=%d discriminator_loss=%f real_acc=%f fake_acc=%f\"\n",
    "                % (epoch, disc_loss, real, fake))\n",
    "\n",
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "S9jhuPJK-703"
   },
   "outputs": [],
   "source": [
    "seq_len = 700\n",
    "learning_rate = 0.01\n",
    "batch_size = 100\n",
    "EPOCHES = 500\n",
    "discriminator_optimizer = optimizers.Adam(learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "ec5wj8J8NNHq"
   },
   "outputs": [],
   "source": [
    "#upload weights.csv to colab\n",
    "w,v,b=np.loadtxt('weights.csv',delimiter=',')\n",
    "w = tf.expand_dims(w,-1)\n",
    "v = tf.expand_dims(v,-1)\n",
    "b = tf.expand_dims(b,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "NWDNT8MzOec_",
    "outputId": "6c1e1581-2078-4046-b458-927f33c89271"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "x = tf.math.log(gen_gaps(w, v, b, 1000))\n",
    "y = tf.math.log(gen_gaps_real(1000))\n",
    "plt.hist(x.numpy().reshape(-1),label = 'fake')\n",
    "plt.hist(y.numpy().reshape(-1), alpha=0.4,label='real')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = gen_gaps(w, v, b, 1000)\n",
    "y = gen_gaps_real(1000)\n",
    "plt.hist(x.numpy().reshape(-1),label = 'fake')\n",
    "plt.hist(y.numpy().reshape(-1), alpha=0.4,label='real')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 503
    },
    "id": "LN8jwzyXLxoW",
    "outputId": "d0b2b7c7-d9f1-42f8-d287-842ec8fce0e5",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"discriminator\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "locally_connected1d (Locally (None, 697, 128)          446080    \n",
      "_________________________________________________________________\n",
      "re_lu (ReLU)                 (None, 697, 128)          0         \n",
      "_________________________________________________________________\n",
      "locally_connected1d_1 (Local (None, 694, 64)           22785408  \n",
      "_________________________________________________________________\n",
      "re_lu_1 (ReLU)               (None, 694, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 44416)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 44417     \n",
      "=================================================================\n",
      "Total params: 23,275,905\n",
      "Trainable params: 23,275,905\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "discriminator = Sequential(\n",
    "    [\n",
    "     Input(shape=(seq_len,1)),\n",
    "     LocallyConnected1D(128, 4),\n",
    "#      BatchNormalization(),\n",
    "     ReLU(),\n",
    "#      MaxPooling1D(),\n",
    "     LocallyConnected1D(64, 4),\n",
    "     ReLU(),\n",
    "#      MaxPooling1D(),\n",
    "#      BatchNormalization(),\n",
    "     Flatten(),\n",
    "     Dense(1)\n",
    "    ],\n",
    "    name=\"discriminator\",\n",
    ")\n",
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "3XQB77QPNFVt",
    "outputId": "ea604227-c9bc-4685-8265-ad60c7e63bcd"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    <ipython-input-2-f8f78fe8de93>:8 training_step  *\n        d_x_true = discriminator(tf.expand_dims(tf.math.log(real_seq),-1))\n    /home/guojp/miniconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py:976 __call__  **\n        self.name)\n    /home/guojp/miniconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/input_spec.py:180 assert_input_compatibility\n        str(x.shape.as_list()))\n\n    ValueError: Input 0 of layer discriminator is incompatible with the layer: expected ndim=3, found ndim=4. Full shape received: [100, 700, 1, 1]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-ff8ce7b54487>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mreal_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mfake_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtraining\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEPOCHES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-2-f8f78fe8de93>\u001b[0m in \u001b[0;36mtraining\u001b[0;34m(epoches)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoches\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mdisc_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mreal\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfake\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiscriminator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0md_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdisc_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mreal_acc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    821\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 823\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    824\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    695\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    696\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 697\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    698\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2853\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2854\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2855\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2856\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3212\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3213\u001b[0;31m       \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3214\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3215\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3073\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3074\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3075\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3076\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3077\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 986\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    987\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    598\u001b[0m         \u001b[0;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    601\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    971\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    972\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 973\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    974\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    975\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    <ipython-input-2-f8f78fe8de93>:8 training_step  *\n        d_x_true = discriminator(tf.expand_dims(tf.math.log(real_seq),-1))\n    /home/guojp/miniconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py:976 __call__  **\n        self.name)\n    /home/guojp/miniconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/input_spec.py:180 assert_input_compatibility\n        str(x.shape.as_list()))\n\n    ValueError: Input 0 of layer discriminator is incompatible with the layer: expected ndim=3, found ndim=4. Full shape received: [100, 700, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "d_loss = []\n",
    "real_acc = []\n",
    "fake_acc = []\n",
    "training(EPOCHES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 461
    },
    "id": "Ud8R_l_Gae02",
    "outputId": "cbfbfcf8-e5e9-4ca9-ae9a-0cda58f96f0c"
   },
   "outputs": [],
   "source": [
    "B = 20\n",
    "W = np.hamming(B)\n",
    "W /= W.sum()\n",
    "plt.figure(figsize = (21,8))\n",
    "plt.plot(range(len(real_acc)),np.convolve(real_acc, W, mode='same'),label='real')\n",
    "plt.plot(range(len(real_acc)),np.convolve(fake_acc, W, mode='same'),label='fake')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "train_D.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
